---
title: "Course Project"
author: "Hyf200408"
date: "2020/6/17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Course Project for Practical Machine Learning: Predict the Exercise Manner with Data from Accelerometers

## Executive Summary

Since `classe` variable is multinomial, tree methods are selected to predict exercise manner with data from accelerometers. Simple decision tree, random forest, and boosted decision tree are built and compared, and the random forest had the best performance. Bayes methods, however, do not suit this problem, because data from accelerometers are hightly intercorrelated.

## Fetching data and pre-treatment

Download training data set from the given website, remove NA values, and separate it into training and validation sets.

```{r <preparation>}
library(magrittr)
library(caret)
# Download training data set and read in the data.
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "training.csv")
temp <- read.csv("training.csv", header = TRUE); temp <- temp[,-1]
# Remove NA values.
screen <- (sapply(temp, function(x) sum(is.na(x))) == 0) & (sapply(temp, function(x) sum(x == "")) == 0)
temp <- temp[,screen]; temp <- temp[,-(1:6)]; temp$classe <- as.factor(temp$classe)
# Randomly split the data set into trainig and validation sets.
set.seed(233); DP <- createDataPartition(temp$classe, p = 0.7)[[1]]
train <- temp[DP,]; vali <- temp[-DP,]
```

## Simple decision tree


```{r <simple decision tree>}
set.seed(233)
tree <- train(classe ~ ., method = "rpart", data = train)
predict(tree, train) %>% confusionMatrix(train$classe)
predict(tree, vali) %>% confusionMatrix(vali$classe)
```

## Random forest

```{r <random forest>}
set.seed(233)
rfm <- train(classe ~ ., method = "rf", data = train)
predict(rfm, train) %>% confusionMatrix(train$classe)
predict(rfm, vali) %>% confusionMatrix(vali$classe)
```

## Boosted decision tree

```{r <boosted decision tree>}
set.seed(233)
gbm <- train(classe ~ ., method = "gbm", data = train, verbose = FALSE)
predict(gbm, train) %>% confusionMatrix(train$classe)
predict(gbm, vali) %>% confusionMatrix(vali$classe)
```

Based on the confusion matrices, the random forest performs best among the three methods.